
# Generate a Blog with OpenAI AIP
*What is GPT-3*
GPT-3 is an AI module released by OpenAI in 2020. An Al module is a program trained on a bunch of data to perform a specific task. In this case, GPT-3 was trained to speak like a human and predict what comes next given the context of a sentence, with it's training dataset being 45 terabytes of text from the internet. For reference , if you had to keep writing until your paper hits 45 terabytes in size, you would have to write 22.5 billion pages worth of text.


# Setting up 
*Open Ai Account*
- Create an OpenAi account to access an API Key for using GRi- 3. An API key is an access code we receive to use / access a certain API. 

# Beginning the Project
- At the core of this project, all we'll be doing is sending data with instructions to a server owned by OpenAi, then receiving a response back from that and displaying it. 
*install the package (OpenAi)*
- Install using the ‘pip install openai’

# The core function 
- First we define a function that will be the topic used to generate the paragraph . 
- Create the variable response to store the responses generated by the output of the 'completions.create()' method call in our openai module.

*Now that we have our endpoint, we need to make certain specification’s.*
• First the model → (This will take the model we want to use. We will be using the gpt-3.5 turbo-isntructor' )
• Second is the 'prompt' → (This will take in our ‘paragraph- topics’ argument, but before that  we can tell our model what to do with that argument)
• Third is the 'max-token' → (This initialized token value decides how long the response is goin to be)
• A paragraph that has 300 words has on average of 400 tokens. 
• Our get-3.5 model has a taken limit of 4,909. 
• Fourth is the 'temperature → (This determines the randomness of a response.)
• A higher temperature creates a more creative response and a lower temperature creates a more direct response. Temperature is valued at any float number between 0-1

• '0': The same response every-time. 
• '1': A different response every-time.

*Now that we have our model setup, we can run our function, and the following things will happen.* 
- OpenAI module will receive our API key along with the specified objects inside our variable 'response' and will send a requests to the completion endpoint - OpenAI will  verify that we can use the get-35 turbo instructor by verifying our APS key.
- After verification , our mode will use the specified field in our response variable to produce a response. 
- The  product response will be returned back in the form of an object and stored in the response variable.

# Multiple Paragraphs 
*Adding additional scripts to generate multiple responses.* 
- Assign a variable the "True” boolean so that it can be used in a white-loop to check user input and see it any condition is met. 

# Rate - Limit 
- Since we are using a white loop until a certain condition is met, we have the potential to be rate limited. 
- Rate Limit is the number of API calls an app or user can make within a given time, period.
- The rate limit for our model is 20 request per minute 


# Credit Limit 
- The more you use this model, the more you exceed your credit limit and will have to purchase more
- So in order to purchase more credits, you need to go to your accounts plan and billing details. 

# Securing  our app. 
- Since we signed in bur OpenAI account to access this API key, other unwanted individuals have the potential chance to access our API  throng our API key. And if these unwanted individuals have access  to our key, they will also have access to our gpt-3  model enabling them to use the server with our key, and we will be the ones charger with many unwanted fees. 

**Install python - dotenv package**
- The puthon-dotenv is a package that allows us to create and use environment variables with-out having to set them in the perating system manually. 
- Install the dotenv package so that we can create a file to hold our environment variable.
- Create a file corresponding to the package (.env) to hide our API key inside the 'API_KEY' variable in the .env five
- Return back to your .py file and from the dotenv package, import ‘dotenv_values’ method to create a path to our .env file and return us a dictionary with all the variables in our .env file.
- We can create a variable to hold our dictionary 
- We then can assign our OpenAI method (api_key) the value of our key (API_KEY)